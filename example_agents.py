import logging
from collections.abc import Mapping
from typing import Any, Callable, Optional

from google.adk.agents import LlmAgent
from google.adk.agents.callback_context import CallbackContext
from google.adk.models import LlmRequest, LlmResponse
import google.genai.types as types

# å•Ÿç”¨è©³ç´°æ—¥èªŒè¼¸å‡ºï¼Œæ–¹ä¾¿åœ¨ ADK ç¶²é ç’°å¢ƒè§€å¯Ÿæµç¨‹
logging.basicConfig(level=logging.INFO)

# é è¨­çš„ Gemini æ¨¡å‹è¨­å®š
MODEL = "gemini-1.5-flash"

MAX_PART_PREVIEW = 200
MAX_PART_COUNT = 3


def _snapshot_content(content: Any) -> Any:
    """å°‡ Content ç‰©ä»¶è½‰æˆå®¹æ˜“é–±è®€çš„æ‘˜è¦è¡¨ç¤ºã€‚"""
    try:
        role = getattr(content, "role", None)
        parts_summary = []
        parts = getattr(content, "parts", None) or []
        for index, part in enumerate(parts):
            if index >= MAX_PART_COUNT:
                parts_summary.append("â€¦ (truncated)")
                break
            text = getattr(part, "text", None)
            if isinstance(text, str):
                if len(text) > MAX_PART_PREVIEW:
                    parts_summary.append(text[:MAX_PART_PREVIEW] + "â€¦")
                else:
                    parts_summary.append(text)
            else:
                parts_summary.append(str(part))
        snapshot = {"role": role, "parts": parts_summary}
        return snapshot
    except Exception as error:  # pylint: disable=broad-except
        logging.debug("âš ï¸ [snapshot_content] Failed to snapshot content: %s", error, exc_info=True)
        return "<content unavailable>"


def _snapshot_state(state: Any) -> str:
    """ç›¡å¯èƒ½æŠŠ session state åºåˆ—åŒ–æˆå¯è®€å­—ä¸²ã€‚"""
    try:
        if state is None:
            return "{}"

        if isinstance(state, Mapping):
            snapshot = dict(state)
        elif hasattr(state, "to_dict") and callable(getattr(state, "to_dict")):
            snapshot = state.to_dict()
        elif hasattr(state, "__dict__"):
            snapshot = {k: v for k, v in vars(state).items() if not k.startswith("_")}
        else:
            snapshot = state

        if isinstance(snapshot, (dict, list, tuple, set)):
            return repr(snapshot)
        return str(snapshot)
    except Exception as error:  # pylint: disable=broad-except
        logging.debug("âš ï¸ [snapshot_state] Failed to snapshot state: %s", error, exc_info=True)
        return "<state unavailable>"


def _snapshot_context(ctx: CallbackContext) -> str:
    """ç‚º CallbackContext å»ºç«‹æ‘˜è¦ï¼Œé¿å…ç›´æ¥è§¸ç¢°éåŒæ­¥å±¬æ€§ã€‚"""
    try:
        if ctx is None:
            return "{}"

        snapshot: dict[str, Any] = {}
        agent_name = getattr(ctx, "agent_name", None)
        if agent_name:
            snapshot["agent_name"] = agent_name

        invocation_id = getattr(ctx, "invocation_id", None)
        if invocation_id:
            snapshot["invocation_id"] = invocation_id

        if hasattr(ctx, "state"):
            snapshot["state"] = _snapshot_state(ctx.state)

        user_content = getattr(ctx, "user_content", None)
        if user_content is not None:
            snapshot["user_content"] = _snapshot_content(user_content)

        return repr(snapshot)
    except Exception as error:  # pylint: disable=broad-except
        logging.debug("âš ï¸ [snapshot_context] Failed to snapshot context: %s", error, exc_info=True)
        return "<context unavailable>"


class FunctionAgent:
    def __init__(self, name: str, model: str, **kwargs: Any):
        self.name = name
        self.model = model
        self.kwargs = kwargs

    def __call__(self, func: Callable[[CallbackContext, LlmRequest], Optional[LlmResponse]]) -> LlmAgent:
        return LlmAgent(
            name=self.name,
            model=self.model,
            before_model_callback=func,
            **self.kwargs,
        )


async def _process_initial_data(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> Optional[LlmResponse]:
    """
    ç¬¬ä¸€å€‹ FunctionAgentï¼šæŠŠè¼¸å…¥æ–‡å­—è½‰æˆæ•´æ•¸ã€é€²è¡Œè¨ˆç®—ï¼Œä¸¦æŠŠçµæœå¯«é€² session stateã€‚
    """
    logging.info("ğŸš€ğŸš€ [process_initial_data] Startingâ€¦")
    logging.info("ğŸ§¾ [process_initial_data] Context snapshot: %s", _snapshot_context(callback_context))
    logging.info("ğŸ“¥ [process_initial_data] Raw request object: %r", llm_request)
    logging.info("ğŸ—ƒï¸ [process_initial_data] Session state before: %s", _snapshot_state(callback_context.state))

    try:
        latest_content = llm_request.contents[-1]
        latest_part = latest_content.parts[0]
        raw_text = latest_part.text
        logging.info("ğŸ“ [process_initial_data] Raw text from request: %s", raw_text)

        input_value = int(raw_text)
        logging.info("ğŸŒŸ [process_initial_data] Parsed integer value: %s", input_value)

        processed_value = input_value * 2
        logging.info("âœ… [process_initial_data] Processed value (input * 2): %s", processed_value)

        callback_context.state["processed_data"] = processed_value
        logging.info(
            "ğŸ’¾ [process_initial_data] Stored processed_data in session state: %s",
            processed_value,
        )
        logging.info("ğŸ—ƒï¸ [process_initial_data] Session state after: %s", _snapshot_state(callback_context.state))

        response_text = f"è¼¸å…¥å€¼ {input_value} å·²è™•ç†ï¼Œçµæœ {processed_value} å·²å¯«å…¥æœƒè©±ç‹€æ…‹ã€‚"
        logging.info("ğŸ‰ [process_initial_data] Done. Response: %s", response_text)
        return LlmResponse(
            content=types.Content(
                role="model",
                parts=[types.Part(text=response_text)],
            )
        )

    except (ValueError, IndexError, AttributeError) as error:
        logging.error("âš ï¸ [process_initial_data] Error processing input: %s", error)
        return LlmResponse(
            content=types.Content(
                role="model",
                parts=[types.Part(text="éŒ¯èª¤ï¼šè«‹æä¾›å¯ä»¥è§£ææˆæ•´æ•¸çš„æ–‡å­—ã€‚")],
            )
        )
    except Exception as error:  # pylint: disable=broad-except
        logging.error("âŒ [process_initial_data] Unexpected error: %s", error)
        return LlmResponse(
            content=types.Content(
                role="model",
                parts=[types.Part(text=f"è™•ç†è¼¸å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {error}")],
            )
        )


async def _use_and_finalize_data(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> Optional[LlmResponse]:
    """
    ç¬¬äºŒå€‹ FunctionAgentï¼šè®€å– session stateï¼Œå»¶ä¼¸è¨ˆç®—ä¸¦è¼¸å‡ºæœ€çµ‚çµæœã€‚
    """
    logging.info("ğŸš€ğŸš€ [use_and_finalize_data] Startingâ€¦")
    logging.info("ğŸ§¾ [use_and_finalize_data] Context snapshot: %s", _snapshot_context(callback_context))
    logging.info("?? [use_and_finalize_data] Raw request object: %r", llm_request)
    logging.info("ğŸ—ƒï¸ [use_and_finalize_data] Session state snapshot: %s", _snapshot_state(callback_context.state))

    processed_data = callback_context.state.get("processed_data")
    logging.info("ğŸ“¦ [use_and_finalize_data] Retrieved processed_data: %s", processed_data)

    if processed_data is not None:
        final_result = processed_data + 10
        logging.info(
            "âœ¨ [use_and_finalize_data] Final result (processed_data + 10): %s",
            final_result,
        )

        response_text = f"å¾æœƒè©±ç‹€æ…‹è®€å–è³‡æ–™ {processed_data}ï¼Œæœ€çµ‚çµæœç‚º {final_result}ã€‚"
        logging.info("ğŸ‰ [use_and_finalize_data] Done. Response: %s", response_text)
        return LlmResponse(
            content=types.Content(
                role="model",
                parts=[types.Part(text=response_text)],
            )
        )

    logging.warning("âš ï¸ [use_and_finalize_data] 'processed_data' not found in session state.")
    return LlmResponse(
        content=types.Content(
            role="model",
            parts=[types.Part(text="éŒ¯èª¤ï¼šæœƒè©±ç‹€æ…‹ä¸­æ‰¾ä¸åˆ° 'processed_data'ã€‚")],
        )
    )


def create_process_initial_data_agent() -> LlmAgent:
    """å›å‚³æ–°çš„ process_initial_data ä»£ç†å¯¦ä¾‹ã€‚"""

    async def handler(callback_context: CallbackContext, llm_request: LlmRequest) -> Optional[LlmResponse]:
        return await _process_initial_data(callback_context, llm_request)

    return FunctionAgent(name="process_initial_data", model=MODEL)(handler)


def create_use_and_finalize_data_agent() -> LlmAgent:
    """å›å‚³æ–°çš„ use_and_finalize_data ä»£ç†å¯¦ä¾‹ã€‚"""

    async def handler(callback_context: CallbackContext, llm_request: LlmRequest) -> Optional[LlmResponse]:
        return await _use_and_finalize_data(callback_context, llm_request)

    return FunctionAgent(name="use_and_finalize_data", model=MODEL)(handler)


# åƒè€ƒï¼šè‹¥æƒ³è‡ªè¡Œä¸²èµ·æ•´å€‹æµç¨‹ï¼Œå¯é€™æ¨£ä½¿ç”¨ï¼š
# root_agent = SequentialAgent(
#     name="data_flow_example",
#     sub_agents=[
#         create_process_initial_data_agent(),
#         create_use_and_finalize_data_agent(),
#     ],
# )

# ç¯„ä¾‹æ“ä½œæ­¥é©Ÿï¼ˆå¦‚åœ¨ notebook æ¸¬è©¦ï¼‰ï¼š
# request = LlmRequest(text="5")
# context = CallbackContext()
# response1 = await create_process_initial_data_agent()(context, request)
# response2 = await create_use_and_finalize_data_agent()(context, request)
# print(response2, context.state)
